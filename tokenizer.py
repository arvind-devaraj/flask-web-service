def tokenizer(text):
	return text.lower().split(' ')